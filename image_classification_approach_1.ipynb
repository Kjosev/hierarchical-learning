{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjosev\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up options\n",
    "\n",
    "options = {}\n",
    "options['margin'] = 50000\n",
    "options['lrate'] = 0.05\n",
    "options['dim'] = 250\n",
    "options['hp_epochs'] = 200\n",
    "options['ic_epochs'] = 50\n",
    "options['batch_size'] = 256\n",
    "options['dataset'] = 'awa2'\n",
    "options['num_base_classes'] = 50\n",
    "options['abs'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the seed\n",
    "np.random.seed(12345)\n",
    "tf.set_random_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of base and parent classes: 106\n",
      "Number of hypernym pairs: 1332\n"
     ]
    }
   ],
   "source": [
    "# HYPERNYM PREDICTION DATA\n",
    "hypernyms, name2index = load_hypernym_dataset(options['dataset'], \n",
    "                                              options['num_base_classes'])\n",
    "\n",
    "options['num_all_classes'] = len(name2index)\n",
    "\n",
    "# one hot encoding for each class with hierarchy \n",
    "hypernyms_per_class = get_hypernyms_per_class(\n",
    "        hypernyms, options['num_base_classes'], options['num_all_classes'])\n",
    "\n",
    "print('Number of base and parent classes:', len(name2index))\n",
    "print('Number of hypernym pairs:', len(hypernyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (37322, 4096)\n",
      "Train size: 29857\n",
      "Validation size: 3733\n",
      "Test size: 3732\n"
     ]
    }
   ],
   "source": [
    "# IMAGE CLASSIFICATION DATA\n",
    "X, labels = load_data()\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, labels)\n",
    "\n",
    "print('Dataset size:', X.shape)\n",
    "print('Train size:', len(X_train))\n",
    "print('Validation size:', len(X_val))\n",
    "print('Test size:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our Adam optimizer \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=options['lrate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERNYM PREDICTION MODEL\n",
    "pos_ch = tf.placeholder(tf.int64, shape=[None])\n",
    "pos_pr = tf.placeholder(tf.int64, shape=[None])\n",
    "neg_ch = tf.placeholder(tf.int64, shape=[None])\n",
    "neg_pr = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "hypernym_model = get_hypernym_model(pos_ch, pos_pr, neg_ch, neg_pr, options)\n",
    "\n",
    "(h_acc, pos_acc, neg_acc), _, h_loss = hypernym_model\n",
    "\n",
    "# hypernym prediction model only updates W_c weights\n",
    "h_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"hyp\")    \n",
    "h_train_op = optimizer.minimize(h_loss, var_list=h_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE CLASSIFICATION MODEL\n",
    "im = tf.placeholder(tf.float64, shape=[None, X.shape[1]])\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "classification_model = get_classification_model(im, y, options)\n",
    "\n",
    "cls_acc, _, cls_loss, cls_pred = classification_model\n",
    "\n",
    "# top 10 predictions\n",
    "flat_hit_pred = get_prediction(im, 10, options) \n",
    "\n",
    "# get errors for all classes\n",
    "cls_all_errors = get_classification_errors_all_classes(im, options) \n",
    "\n",
    "# image classification model only updates W_i weights\n",
    "cls_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"cls\")        \n",
    "cls_train_op = optimizer.minimize(cls_loss, var_list=cls_vars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our tf session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# initialize weights\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Steps: 00000 Currernt loss 12799999.041901 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 2\n",
      "Steps: 00010 Currernt loss 12793704.795062 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 3\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 4\n",
      "Steps: 00020 Currernt loss 12773693.931111 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 5\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 6\n",
      "Steps: 00030 Currernt loss 12734652.869457 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 7\n",
      "Steps: 00040 Currernt loss 12671128.373767 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 8\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 9\n",
      "Steps: 00050 Currernt loss 12571064.250095 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 10\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 11\n",
      "Steps: 00060 Currernt loss 12447269.678845 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 12\n",
      "Steps: 00070 Currernt loss 12300952.469104 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 13\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 14\n",
      "Steps: 00080 Currernt loss 12075968.581322 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 15\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 16\n",
      "Steps: 00090 Currernt loss 11807969.464669 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 17\n",
      "Steps: 00100 Currernt loss 11562876.310836 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 18\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 19\n",
      "Steps: 00110 Currernt loss 11278298.348457 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 20\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 21\n",
      "Steps: 00120 Currernt loss 10906174.433901 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 22\n",
      "Steps: 00130 Currernt loss 10685924.419531 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 23\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 24\n",
      "Steps: 00140 Currernt loss 10331508.314510 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 25\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0\n",
      "Train Accuracy:  0.5\n",
      "Epoch: 26\n",
      "Steps: 00150 Currernt loss 9653973.054985 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0007507507507507524\n",
      "Train Accuracy:  0.5003753753753754\n",
      "Epoch: 27\n",
      "Steps: 00160 Currernt loss 9143046.525291 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.0037537537537537524\n",
      "Train Accuracy:  0.5018768768768769\n",
      "Epoch: 28\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.006756756756756757\n",
      "Train Accuracy:  0.5033783783783784\n",
      "Epoch: 29\n",
      "Steps: 00170 Currernt loss 8760815.726299 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.015765765765765764\n",
      "Train Accuracy:  0.5078828828828829\n",
      "Epoch: 30\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.022522522522522525\n",
      "Train Accuracy:  0.5112612612612613\n",
      "Epoch: 31\n",
      "Steps: 00180 Currernt loss 8119518.726162 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.04504504504504504\n",
      "Train Accuracy:  0.5225225225225225\n",
      "Epoch: 32\n",
      "Steps: 00190 Currernt loss 7681691.326557 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.048798798798798795\n",
      "Train Accuracy:  0.5243993993993994\n",
      "Epoch: 33\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.05705705705705706\n",
      "Train Accuracy:  0.5285285285285286\n",
      "Epoch: 34\n",
      "Steps: 00200 Currernt loss 7439329.912854 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.09309309309309309\n",
      "Train Accuracy:  0.5465465465465466\n",
      "Epoch: 35\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.10435435435435435\n",
      "Train Accuracy:  0.5521771771771772\n",
      "Epoch: 36\n",
      "Steps: 00210 Currernt loss 6632895.132543 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.12537537537537538\n",
      "Train Accuracy:  0.5626876876876876\n",
      "Epoch: 37\n",
      "Steps: 00220 Currernt loss 6579725.904750 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.12162162162162161\n",
      "Train Accuracy:  0.5608108108108109\n",
      "Epoch: 38\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.16216216216216217\n",
      "Train Accuracy:  0.581081081081081\n",
      "Epoch: 39\n",
      "Steps: 00230 Currernt loss 5530532.721231 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.1659159159159159\n",
      "Train Accuracy:  0.5829579579579579\n",
      "Epoch: 40\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.1899399399399399\n",
      "Train Accuracy:  0.59496996996997\n",
      "Epoch: 41\n",
      "Steps: 00240 Currernt loss 5787638.434707 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.2027027027027027\n",
      "Train Accuracy:  0.6013513513513514\n",
      "Epoch: 42\n",
      "Steps: 00250 Currernt loss 5117177.331725 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.24474474474474475\n",
      "Train Accuracy:  0.6223723723723724\n",
      "Epoch: 43\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.25\n",
      "Train Accuracy:  0.625\n",
      "Epoch: 44\n",
      "Steps: 00260 Currernt loss 5151722.391444 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.26201201201201196\n",
      "Train Accuracy:  0.631006006006006\n",
      "Epoch: 45\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.2867867867867868\n",
      "Train Accuracy:  0.6433933933933934\n",
      "Epoch: 46\n",
      "Steps: 00270 Currernt loss 4501242.168677 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.30405405405405406\n",
      "Train Accuracy:  0.652027027027027\n",
      "Epoch: 47\n",
      "Steps: 00280 Currernt loss 4639028.030816 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.32657657657657657\n",
      "Train Accuracy:  0.6632882882882883\n",
      "Epoch: 48\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.3611111111111111\n",
      "Train Accuracy:  0.6805555555555555\n",
      "Epoch: 49\n",
      "Steps: 00290 Currernt loss 4102651.801890 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.37237237237237236\n",
      "Train Accuracy:  0.6861861861861861\n",
      "Epoch: 50\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.3791291291291291\n",
      "Train Accuracy:  0.6895645645645645\n",
      "Epoch: 51\n",
      "Steps: 00300 Currernt loss 4472143.651433 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.38513513513513514\n",
      "Train Accuracy:  0.6925675675675677\n",
      "Epoch: 52\n",
      "Steps: 00310 Currernt loss 3825282.618650 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.43093093093093093\n",
      "Train Accuracy:  0.7154654654654655\n",
      "Epoch: 53\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.4189189189189189\n",
      "Train Accuracy:  0.7094594594594595\n",
      "Epoch: 54\n",
      "Steps: 00320 Currernt loss 4019442.369636 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.4421921921921922\n",
      "Train Accuracy:  0.721096096096096\n",
      "Epoch: 55\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.4534534534534534\n",
      "Train Accuracy:  0.7267267267267268\n",
      "Epoch: 56\n",
      "Steps: 00330 Currernt loss 4016329.566290 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.4797297297297297\n",
      "Train Accuracy:  0.7398648648648649\n",
      "Epoch: 57\n",
      "Steps: 00340 Currernt loss 3782608.055855 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.49099099099099097\n",
      "Train Accuracy:  0.7454954954954955\n",
      "Epoch: 58\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.4887387387387387\n",
      "Train Accuracy:  0.7443693693693695\n",
      "Epoch: 59\n",
      "Steps: 00350 Currernt loss 3086205.560167 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5112612612612613\n",
      "Train Accuracy:  0.7556306306306306\n",
      "Epoch: 60\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5030030030030029\n",
      "Train Accuracy:  0.7515015015015014\n",
      "Epoch: 61\n",
      "Steps: 00360 Currernt loss 3112262.040157 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5548048048048049\n",
      "Train Accuracy:  0.7774024024024024\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 00370 Currernt loss 3755686.833205 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5510510510510511\n",
      "Train Accuracy:  0.7755255255255256\n",
      "Epoch: 63\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5457957957957957\n",
      "Train Accuracy:  0.7728978978978978\n",
      "Epoch: 64\n",
      "Steps: 00380 Currernt loss 2734438.414653 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5630630630630631\n",
      "Train Accuracy:  0.7815315315315314\n",
      "Epoch: 65\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5968468468468469\n",
      "Train Accuracy:  0.7984234234234235\n",
      "Epoch: 66\n",
      "Steps: 00390 Currernt loss 3064749.512524 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5870870870870871\n",
      "Train Accuracy:  0.7935435435435435\n",
      "Epoch: 67\n",
      "Steps: 00400 Currernt loss 3842985.867972 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5660660660660661\n",
      "Train Accuracy:  0.783033033033033\n",
      "Epoch: 68\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.5900900900900902\n",
      "Train Accuracy:  0.7950450450450449\n",
      "Epoch: 69\n",
      "Steps: 00410 Currernt loss 3450541.074002 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.617867867867868\n",
      "Train Accuracy:  0.808933933933934\n",
      "Epoch: 70\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6291291291291291\n",
      "Train Accuracy:  0.8145645645645646\n",
      "Epoch: 71\n",
      "Steps: 00420 Currernt loss 3417599.686257 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6073573573573573\n",
      "Train Accuracy:  0.8036786786786787\n",
      "Epoch: 72\n",
      "Steps: 00430 Currernt loss 3105677.642959 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6216216216216216\n",
      "Train Accuracy:  0.8108108108108107\n",
      "Epoch: 73\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6381381381381381\n",
      "Train Accuracy:  0.8190690690690691\n",
      "Epoch: 74\n",
      "Steps: 00440 Currernt loss 2435699.136996 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6584084084084084\n",
      "Train Accuracy:  0.829204204204204\n",
      "Epoch: 75\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6403903903903904\n",
      "Train Accuracy:  0.8201951951951951\n",
      "Epoch: 76\n",
      "Steps: 00450 Currernt loss 3279744.804078 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6463963963963963\n",
      "Train Accuracy:  0.8231981981981982\n",
      "Epoch: 77\n",
      "Steps: 00460 Currernt loss 2688647.198133 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6584084084084085\n",
      "Train Accuracy:  0.8292042042042042\n",
      "Epoch: 78\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6756756756756757\n",
      "Train Accuracy:  0.8378378378378377\n",
      "Epoch: 79\n",
      "Steps: 00470 Currernt loss 2186470.884259 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.680930930930931\n",
      "Train Accuracy:  0.8404654654654654\n",
      "Epoch: 80\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6606606606606606\n",
      "Train Accuracy:  0.8303303303303302\n",
      "Epoch: 81\n",
      "Steps: 00480 Currernt loss 2499308.450336 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6809309309309308\n",
      "Train Accuracy:  0.8404654654654655\n",
      "Epoch: 82\n",
      "Steps: 00490 Currernt loss 2912392.332082 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6764264264264265\n",
      "Train Accuracy:  0.8382132132132132\n",
      "Epoch: 83\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6809309309309309\n",
      "Train Accuracy:  0.8404654654654653\n",
      "Epoch: 84\n",
      "Steps: 00500 Currernt loss 3250811.236348 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6914414414414414\n",
      "Train Accuracy:  0.8457207207207207\n",
      "Epoch: 85\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7019519519519519\n",
      "Train Accuracy:  0.850975975975976\n",
      "Epoch: 86\n",
      "Steps: 00510 Currernt loss 3304864.739422 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.674924924924925\n",
      "Train Accuracy:  0.8374624624624624\n",
      "Epoch: 87\n",
      "Steps: 00520 Currernt loss 2961378.246176 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6899399399399399\n",
      "Train Accuracy:  0.8449699699699699\n",
      "Epoch: 88\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6839339339339339\n",
      "Train Accuracy:  0.8419669669669669\n",
      "Epoch: 89\n",
      "Steps: 00530 Currernt loss 2909168.288609 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7072072072072072\n",
      "Train Accuracy:  0.8536036036036035\n",
      "Epoch: 90\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7154654654654654\n",
      "Train Accuracy:  0.8577327327327328\n",
      "Epoch: 91\n",
      "Steps: 00540 Currernt loss 3120769.218687 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.701951951951952\n",
      "Train Accuracy:  0.850975975975976\n",
      "Epoch: 92\n",
      "Steps: 00550 Currernt loss 2550888.446012 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7184684684684683\n",
      "Train Accuracy:  0.8592342342342343\n",
      "Epoch: 93\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7207207207207207\n",
      "Train Accuracy:  0.8603603603603603\n",
      "Epoch: 94\n",
      "Steps: 00560 Currernt loss 3220283.477157 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7102102102102102\n",
      "Train Accuracy:  0.8551051051051051\n",
      "Epoch: 95\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.6944444444444445\n",
      "Train Accuracy:  0.8472222222222222\n",
      "Epoch: 96\n",
      "Steps: 00570 Currernt loss 2436419.456088 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.737987987987988\n",
      "Train Accuracy:  0.868993993993994\n",
      "Epoch: 97\n",
      "Steps: 00580 Currernt loss 2745081.797200 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7327327327327328\n",
      "Train Accuracy:  0.8663663663663663\n",
      "Epoch: 98\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.710960960960961\n",
      "Train Accuracy:  0.8554804804804804\n",
      "Epoch: 99\n",
      "Steps: 00590 Currernt loss 2901725.672638 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7064564564564564\n",
      "Train Accuracy:  0.8532282282282282\n",
      "Epoch: 100\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7424924924924925\n",
      "Train Accuracy:  0.8712462462462462\n",
      "Epoch: 101\n",
      "Steps: 00600 Currernt loss 2971160.390898 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7147147147147147\n",
      "Train Accuracy:  0.8573573573573574\n",
      "Epoch: 102\n",
      "Steps: 00610 Currernt loss 2852487.487096 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7432432432432433\n",
      "Train Accuracy:  0.8716216216216215\n",
      "Epoch: 103\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7484984984984984\n",
      "Train Accuracy:  0.8742492492492493\n",
      "Epoch: 104\n",
      "Steps: 00620 Currernt loss 2640213.596635 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7612612612612613\n",
      "Train Accuracy:  0.8806306306306306\n",
      "Epoch: 105\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7409909909909911\n",
      "Train Accuracy:  0.8704954954954955\n",
      "Epoch: 106\n",
      "Steps: 00630 Currernt loss 3051525.869807 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7402402402402404\n",
      "Train Accuracy:  0.8701201201201201\n",
      "Epoch: 107\n",
      "Steps: 00640 Currernt loss 2835446.325918 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7477477477477478\n",
      "Train Accuracy:  0.8738738738738738\n",
      "Epoch: 108\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7522522522522522\n",
      "Train Accuracy:  0.8761261261261262\n",
      "Epoch: 109\n",
      "Steps: 00650 Currernt loss 2740594.269042 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7297297297297297\n",
      "Train Accuracy:  0.8648648648648649\n",
      "Epoch: 110\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7687687687687687\n",
      "Train Accuracy:  0.8843843843843844\n",
      "Epoch: 111\n",
      "Steps: 00660 Currernt loss 2685869.103753 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7432432432432432\n",
      "Train Accuracy:  0.8716216216216216\n",
      "Epoch: 112\n",
      "Steps: 00670 Currernt loss 2515777.185723 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7432432432432433\n",
      "Train Accuracy:  0.8716216216216215\n",
      "Epoch: 113\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7522522522522521\n",
      "Train Accuracy:  0.8761261261261262\n",
      "Epoch: 114\n",
      "Steps: 00680 Currernt loss 2435667.693064 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.743993993993994\n",
      "Train Accuracy:  0.8719969969969971\n",
      "Epoch: 115\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7597597597597597\n",
      "Train Accuracy:  0.8798798798798798\n",
      "Epoch: 116\n",
      "Steps: 00690 Currernt loss 2204660.160059 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7657657657657657\n",
      "Train Accuracy:  0.882882882882883\n",
      "Epoch: 117\n",
      "Steps: 00700 Currernt loss 2424889.878385 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7642642642642643\n",
      "Train Accuracy:  0.882132132132132\n",
      "Epoch: 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7237237237237237\n",
      "Train Accuracy:  0.8618618618618619\n",
      "Epoch: 119\n",
      "Steps: 00710 Currernt loss 2313952.145577 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7710210210210209\n",
      "Train Accuracy:  0.8855105105105106\n",
      "Epoch: 120\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7462462462462464\n",
      "Train Accuracy:  0.8731231231231231\n",
      "Epoch: 121\n",
      "Steps: 00720 Currernt loss 2023344.570827 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7657657657657657\n",
      "Train Accuracy:  0.882882882882883\n",
      "Epoch: 122\n",
      "Steps: 00730 Currernt loss 2707063.534070 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7635135135135136\n",
      "Train Accuracy:  0.8817567567567567\n",
      "Epoch: 123\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7852852852852853\n",
      "Train Accuracy:  0.8926426426426426\n",
      "Epoch: 124\n",
      "Steps: 00740 Currernt loss 2212299.862314 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7717717717717718\n",
      "Train Accuracy:  0.8858858858858859\n",
      "Epoch: 125\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7627627627627628\n",
      "Train Accuracy:  0.8813813813813813\n",
      "Epoch: 126\n",
      "Steps: 00750 Currernt loss 2269067.844579 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7627627627627629\n",
      "Train Accuracy:  0.8813813813813813\n",
      "Epoch: 127\n",
      "Steps: 00760 Currernt loss 2165846.194534 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7545045045045045\n",
      "Train Accuracy:  0.8772522522522522\n",
      "Epoch: 128\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7590090090090089\n",
      "Train Accuracy:  0.8795045045045045\n",
      "Epoch: 129\n",
      "Steps: 00770 Currernt loss 2580886.423020 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.765015015015015\n",
      "Train Accuracy:  0.8825075075075075\n",
      "Epoch: 130\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7680180180180181\n",
      "Train Accuracy:  0.8840090090090089\n",
      "Epoch: 131\n",
      "Steps: 00780 Currernt loss 2313353.937516 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7702702702702703\n",
      "Train Accuracy:  0.8851351351351351\n",
      "Epoch: 132\n",
      "Steps: 00790 Currernt loss 2248788.823104 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.777027027027027\n",
      "Train Accuracy:  0.8885135135135134\n",
      "Epoch: 133\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7897897897897899\n",
      "Train Accuracy:  0.8948948948948948\n",
      "Epoch: 134\n",
      "Steps: 00800 Currernt loss 2220800.824935 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7755255255255256\n",
      "Train Accuracy:  0.8877627627627628\n",
      "Epoch: 135\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7680180180180181\n",
      "Train Accuracy:  0.884009009009009\n",
      "Epoch: 136\n",
      "Steps: 00810 Currernt loss 1877091.162078 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7657657657657657\n",
      "Train Accuracy:  0.8828828828828829\n",
      "Epoch: 137\n",
      "Steps: 00820 Currernt loss 2550931.662349 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7822822822822822\n",
      "Train Accuracy:  0.8911411411411412\n",
      "Epoch: 138\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7837837837837839\n",
      "Train Accuracy:  0.8918918918918919\n",
      "Epoch: 139\n",
      "Steps: 00830 Currernt loss 2482108.733968 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7770270270270272\n",
      "Train Accuracy:  0.8885135135135135\n",
      "Epoch: 140\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7882882882882883\n",
      "Train Accuracy:  0.8941441441441441\n",
      "Epoch: 141\n",
      "Steps: 00840 Currernt loss 2599010.836955 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7710210210210211\n",
      "Train Accuracy:  0.8855105105105104\n",
      "Epoch: 142\n",
      "Steps: 00850 Currernt loss 2936368.671269 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.786036036036036\n",
      "Train Accuracy:  0.893018018018018\n",
      "Epoch: 143\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7567567567567568\n",
      "Train Accuracy:  0.8783783783783783\n",
      "Epoch: 144\n",
      "Steps: 00860 Currernt loss 2270325.080298 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.783033033033033\n",
      "Train Accuracy:  0.8915165165165165\n",
      "Epoch: 145\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7875375375375375\n",
      "Train Accuracy:  0.8937687687687688\n",
      "Epoch: 146\n",
      "Steps: 00870 Currernt loss 2568605.435519 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7942942942942943\n",
      "Train Accuracy:  0.8971471471471472\n",
      "Epoch: 147\n",
      "Steps: 00880 Currernt loss 2246930.291760 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7950450450450451\n",
      "Train Accuracy:  0.8975225225225225\n",
      "Epoch: 148\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7845345345345346\n",
      "Train Accuracy:  0.8922672672672673\n",
      "Epoch: 149\n",
      "Steps: 00890 Currernt loss 2149821.654318 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7905405405405406\n",
      "Train Accuracy:  0.8952702702702704\n",
      "Epoch: 150\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.795045045045045\n",
      "Train Accuracy:  0.8975225225225225\n",
      "Epoch: 151\n",
      "Steps: 00900 Currernt loss 2005152.580329 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7942942942942943\n",
      "Train Accuracy:  0.897147147147147\n",
      "Epoch: 152\n",
      "Steps: 00910 Currernt loss 2328872.249200 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.81006006006006\n",
      "Train Accuracy:  0.90503003003003\n",
      "Epoch: 153\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7942942942942943\n",
      "Train Accuracy:  0.8971471471471473\n",
      "Epoch: 154\n",
      "Steps: 00920 Currernt loss 2319411.482278 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7785285285285285\n",
      "Train Accuracy:  0.8892642642642643\n",
      "Epoch: 155\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7987987987987988\n",
      "Train Accuracy:  0.8993993993993994\n",
      "Epoch: 156\n",
      "Steps: 00930 Currernt loss 2381344.858216 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7747747747747747\n",
      "Train Accuracy:  0.8873873873873873\n",
      "Epoch: 157\n",
      "Steps: 00940 Currernt loss 2292211.496599 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7890390390390389\n",
      "Train Accuracy:  0.8945195195195195\n",
      "Epoch: 158\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7605105105105104\n",
      "Train Accuracy:  0.8802552552552553\n",
      "Epoch: 159\n",
      "Steps: 00950 Currernt loss 2637745.837748 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7897897897897898\n",
      "Train Accuracy:  0.8948948948948949\n",
      "Epoch: 160\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.798048048048048\n",
      "Train Accuracy:  0.899024024024024\n",
      "Epoch: 161\n",
      "Steps: 00960 Currernt loss 2106864.176343 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7912912912912914\n",
      "Train Accuracy:  0.8956456456456456\n",
      "Epoch: 162\n",
      "Steps: 00970 Currernt loss 2384055.365352 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8018018018018017\n",
      "Train Accuracy:  0.900900900900901\n",
      "Epoch: 163\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7942942942942943\n",
      "Train Accuracy:  0.8971471471471472\n",
      "Epoch: 164\n",
      "Steps: 00980 Currernt loss 2196593.624052 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.807057057057057\n",
      "Train Accuracy:  0.9035285285285285\n",
      "Epoch: 165\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7897897897897899\n",
      "Train Accuracy:  0.8948948948948949\n",
      "Epoch: 166\n",
      "Steps: 00990 Currernt loss 2082292.985041 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8138138138138138\n",
      "Train Accuracy:  0.9069069069069069\n",
      "Epoch: 167\n",
      "Steps: 01000 Currernt loss 2122044.913490 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7950450450450451\n",
      "Train Accuracy:  0.8975225225225224\n",
      "Epoch: 168\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8018018018018018\n",
      "Train Accuracy:  0.9009009009009009\n",
      "Epoch: 169\n",
      "Steps: 01010 Currernt loss 1742888.151326 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.786036036036036\n",
      "Train Accuracy:  0.8930180180180178\n",
      "Epoch: 170\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8048048048048048\n",
      "Train Accuracy:  0.9024024024024023\n",
      "Epoch: 171\n",
      "Steps: 01020 Currernt loss 2937301.431629 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8040540540540541\n",
      "Train Accuracy:  0.9020270270270271\n",
      "Epoch: 172\n",
      "Steps: 01030 Currernt loss 2603385.047541 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8040540540540541\n",
      "Train Accuracy:  0.9020270270270269\n",
      "Epoch: 173\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7935435435435435\n",
      "Train Accuracy:  0.8967717717717718\n",
      "Epoch: 174\n",
      "Steps: 01040 Currernt loss 2441124.955390 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7927927927927928\n",
      "Train Accuracy:  0.8963963963963965\n",
      "Epoch: 175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7867867867867868\n",
      "Train Accuracy:  0.8933933933933934\n",
      "Epoch: 176\n",
      "Steps: 01050 Currernt loss 2074678.126957 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.789039039039039\n",
      "Train Accuracy:  0.8945195195195195\n",
      "Epoch: 177\n",
      "Steps: 01060 Currernt loss 2103957.765470 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7785285285285286\n",
      "Train Accuracy:  0.8892642642642642\n",
      "Epoch: 178\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8228228228228228\n",
      "Train Accuracy:  0.9114114114114112\n",
      "Epoch: 179\n",
      "Steps: 01070 Currernt loss 1877532.524092 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7995495495495496\n",
      "Train Accuracy:  0.8997747747747749\n",
      "Epoch: 180\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8093093093093093\n",
      "Train Accuracy:  0.9046546546546546\n",
      "Epoch: 181\n",
      "Steps: 01080 Currernt loss 1907638.403119 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8175675675675675\n",
      "Train Accuracy:  0.9087837837837838\n",
      "Epoch: 182\n",
      "Steps: 01090 Currernt loss 2037712.321330 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8115615615615616\n",
      "Train Accuracy:  0.9057807807807807\n",
      "Epoch: 183\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8115615615615615\n",
      "Train Accuracy:  0.9057807807807807\n",
      "Epoch: 184\n",
      "Steps: 01100 Currernt loss 2035805.012556 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8078078078078078\n",
      "Train Accuracy:  0.9039039039039038\n",
      "Epoch: 185\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8033033033033032\n",
      "Train Accuracy:  0.9016516516516516\n",
      "Epoch: 186\n",
      "Steps: 01110 Currernt loss 2243806.960852 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8085585585585585\n",
      "Train Accuracy:  0.9042792792792792\n",
      "Epoch: 187\n",
      "Steps: 01120 Currernt loss 2011390.929443 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8085585585585585\n",
      "Train Accuracy:  0.9042792792792792\n",
      "Epoch: 188\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8003003003003003\n",
      "Train Accuracy:  0.90015015015015\n",
      "Epoch: 189\n",
      "Steps: 01130 Currernt loss 2158199.901201 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8145645645645646\n",
      "Train Accuracy:  0.9072822822822824\n",
      "Epoch: 190\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7935435435435436\n",
      "Train Accuracy:  0.8967717717717716\n",
      "Epoch: 191\n",
      "Steps: 01140 Currernt loss 2374383.922061 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8040540540540541\n",
      "Train Accuracy:  0.902027027027027\n",
      "Epoch: 192\n",
      "Steps: 01150 Currernt loss 2063754.155224 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7995495495495495\n",
      "Train Accuracy:  0.8997747747747747\n",
      "Epoch: 193\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8198198198198198\n",
      "Train Accuracy:  0.9099099099099098\n",
      "Epoch: 194\n",
      "Steps: 01160 Currernt loss 2455111.582724 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7920420420420421\n",
      "Train Accuracy:  0.8960210210210211\n",
      "Epoch: 195\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.7882882882882882\n",
      "Train Accuracy:  0.894144144144144\n",
      "Epoch: 196\n",
      "Steps: 01170 Currernt loss 2269934.404241 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8168168168168167\n",
      "Train Accuracy:  0.9084084084084083\n",
      "Epoch: 197\n",
      "Steps: 01180 Currernt loss 2052555.062711 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8025525525525525\n",
      "Train Accuracy:  0.9012762762762763\n",
      "Epoch: 198\n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8145645645645645\n",
      "Train Accuracy:  0.9072822822822821\n",
      "Epoch: 199\n",
      "Steps: 01190 Currernt loss 2037159.185009 \n",
      "Train Positive Accuracy:  1.0\n",
      "Train Negative Accuracy:  0.8048048048048049\n",
      "Train Accuracy:  0.9024024024024024\n"
     ]
    }
   ],
   "source": [
    "# Train the hypernym prediction model\n",
    "\n",
    "hp_steps = 0\n",
    "\n",
    "h_p_acc_list = []\n",
    "h_n_acc_list = []\n",
    "h_acc_list = []\n",
    "h_loss_list = []\n",
    "\n",
    "for epoch in range(1, options['hp_epochs']):\n",
    "    print(\"Epoch:\", epoch)\n",
    "\n",
    "\n",
    "    h_p_acc_avg = 0\n",
    "    h_n_acc_avg = 0\n",
    "    h_acc_avg = 0\n",
    "    h_loss_avg = 0\n",
    "\n",
    "    for batch_idxs in get_batch_idxs(len(hypernyms), options['batch_size']):\n",
    "        positive = hypernyms[batch_idxs]\n",
    "        negative = generate_negative_hypernyms(len(positive), options['num_all_classes'])\n",
    "\n",
    "        #feed to training and get results\n",
    "        _, curr_loss, curr_p_acc, curr_n_acc, curr_acc = sess.run(\n",
    "            [h_train_op, h_loss, pos_acc, neg_acc, h_acc], feed_dict= {\n",
    "                pos_ch: positive[:,0], # children\n",
    "                pos_pr: positive[:,1], # parents\n",
    "                neg_ch: negative[:,0],\n",
    "                neg_pr: negative[:,1]\n",
    "            })\n",
    "    \n",
    "        # update average loss and accuracy\n",
    "        h_p_acc_avg += curr_p_acc * len(batch_idxs) / float(len(hypernyms))\n",
    "        h_n_acc_avg += curr_n_acc * len(batch_idxs) / float(len(hypernyms))\n",
    "        h_acc_avg += curr_acc * len(batch_idxs) / float(len(hypernyms))\n",
    "        h_loss_avg += curr_loss * len(batch_idxs) / float(len(hypernyms))\n",
    "\n",
    "        if hp_steps % 10 == 0:\n",
    "            print(\"Steps: %05d Currernt loss %f \" % (hp_steps, curr_loss))\n",
    "\n",
    "        hp_steps += 1\n",
    "\n",
    "    print(\"Train Positive Accuracy: \", h_p_acc_avg )\n",
    "    print(\"Train Negative Accuracy: \", h_n_acc_avg)\n",
    "    print(\"Train Accuracy: \", h_acc_avg)\n",
    "    \n",
    "    h_p_acc_list.append(h_p_acc_avg)\n",
    "    h_n_acc_list.append(h_n_acc_avg)\n",
    "    h_acc_list.append(h_acc_avg)\n",
    "    h_loss_list.append(h_loss_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Steps: 00010 Accuracy: 0.644531\n",
      "Steps: 00020 Accuracy: 0.679688\n",
      "Steps: 00030 Accuracy: 0.699219\n",
      "Steps: 00040 Accuracy: 0.675781\n",
      "Steps: 00050 Accuracy: 0.726562\n",
      "Steps: 00060 Accuracy: 0.781250\n",
      "Steps: 00070 Accuracy: 0.734375\n",
      "Steps: 00080 Accuracy: 0.718750\n",
      "Steps: 00090 Accuracy: 0.812500\n",
      "Steps: 00100 Accuracy: 0.816406\n",
      "Steps: 00110 Accuracy: 0.777344\n",
      "\n",
      "Train Accuracy: 0.722946 Loss: 140399554.645086\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.803107 \n",
      "\n",
      "Epoch: 2\n",
      "Steps: 00120 Accuracy: 0.781250\n",
      "Steps: 00130 Accuracy: 0.800781\n",
      "Steps: 00140 Accuracy: 0.812500\n",
      "Steps: 00150 Accuracy: 0.828125\n",
      "Steps: 00160 Accuracy: 0.785156\n",
      "Steps: 00170 Accuracy: 0.828125\n",
      "Steps: 00180 Accuracy: 0.839844\n",
      "Steps: 00190 Accuracy: 0.835938\n",
      "Steps: 00200 Accuracy: 0.824219\n",
      "Steps: 00210 Accuracy: 0.781250\n",
      "Steps: 00220 Accuracy: 0.820312\n",
      "Steps: 00230 Accuracy: 0.847656\n",
      "\n",
      "Train Accuracy: 0.815789 Loss: 88252469.236899\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.834450 \n",
      "\n",
      "Epoch: 3\n",
      "Steps: 00240 Accuracy: 0.796875\n",
      "Steps: 00250 Accuracy: 0.843750\n",
      "Steps: 00260 Accuracy: 0.878906\n",
      "Steps: 00270 Accuracy: 0.832031\n",
      "Steps: 00280 Accuracy: 0.832031\n",
      "Steps: 00290 Accuracy: 0.808594\n",
      "Steps: 00300 Accuracy: 0.820312\n",
      "Steps: 00310 Accuracy: 0.855469\n",
      "Steps: 00320 Accuracy: 0.859375\n",
      "Steps: 00330 Accuracy: 0.796875\n",
      "Steps: 00340 Accuracy: 0.832031\n",
      "Steps: 00350 Accuracy: 0.867188\n",
      "\n",
      "Train Accuracy: 0.835884 Loss: 74489397.791675\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.842754 \n",
      "\n",
      "Epoch: 4\n",
      "Steps: 00360 Accuracy: 0.878906\n",
      "Steps: 00370 Accuracy: 0.835938\n",
      "Steps: 00380 Accuracy: 0.867188\n",
      "Steps: 00390 Accuracy: 0.855469\n",
      "Steps: 00400 Accuracy: 0.839844\n",
      "Steps: 00410 Accuracy: 0.898438\n",
      "Steps: 00420 Accuracy: 0.871094\n",
      "Steps: 00430 Accuracy: 0.863281\n",
      "Steps: 00440 Accuracy: 0.855469\n",
      "Steps: 00450 Accuracy: 0.890625\n",
      "Steps: 00460 Accuracy: 0.878906\n",
      "\n",
      "Train Accuracy: 0.852162 Loss: 66728644.363318\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.849987 \n",
      "\n",
      "Epoch: 5\n",
      "Steps: 00470 Accuracy: 0.890625\n",
      "Steps: 00480 Accuracy: 0.832031\n",
      "Steps: 00490 Accuracy: 0.832031\n",
      "Steps: 00500 Accuracy: 0.792969\n",
      "Steps: 00510 Accuracy: 0.871094\n",
      "Steps: 00520 Accuracy: 0.851562\n",
      "Steps: 00530 Accuracy: 0.878906\n",
      "Steps: 00540 Accuracy: 0.886719\n",
      "Steps: 00550 Accuracy: 0.863281\n",
      "Steps: 00560 Accuracy: 0.875000\n",
      "Steps: 00570 Accuracy: 0.902344\n",
      "Steps: 00580 Accuracy: 0.882812\n",
      "\n",
      "Train Accuracy: 0.859430 Loss: 61819007.500335\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.852665 \n",
      "\n",
      "Epoch: 6\n",
      "Steps: 00590 Accuracy: 0.894531\n",
      "Steps: 00600 Accuracy: 0.851562\n",
      "Steps: 00610 Accuracy: 0.863281\n",
      "Steps: 00620 Accuracy: 0.851562\n",
      "Steps: 00630 Accuracy: 0.863281\n",
      "Steps: 00640 Accuracy: 0.867188\n",
      "Steps: 00650 Accuracy: 0.867188\n",
      "Steps: 00660 Accuracy: 0.843750\n",
      "Steps: 00670 Accuracy: 0.894531\n",
      "Steps: 00680 Accuracy: 0.894531\n",
      "Steps: 00690 Accuracy: 0.832031\n",
      "Steps: 00700 Accuracy: 0.832031\n",
      "\n",
      "Train Accuracy: 0.866430 Loss: 58184506.457811\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.855344 \n",
      "\n",
      "Epoch: 7\n",
      "Steps: 00710 Accuracy: 0.820312\n",
      "Steps: 00720 Accuracy: 0.851562\n",
      "Steps: 00730 Accuracy: 0.859375\n",
      "Steps: 00740 Accuracy: 0.863281\n",
      "Steps: 00750 Accuracy: 0.882812\n",
      "Steps: 00760 Accuracy: 0.875000\n",
      "Steps: 00770 Accuracy: 0.875000\n",
      "Steps: 00780 Accuracy: 0.929688\n",
      "Steps: 00790 Accuracy: 0.894531\n",
      "Steps: 00800 Accuracy: 0.886719\n",
      "Steps: 00810 Accuracy: 0.882812\n",
      "\n",
      "Train Accuracy: 0.873028 Loss: 55218292.150193\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.857219 \n",
      "\n",
      "Epoch: 8\n",
      "Steps: 00820 Accuracy: 0.894531\n",
      "Steps: 00830 Accuracy: 0.859375\n",
      "Steps: 00840 Accuracy: 0.835938\n",
      "Steps: 00850 Accuracy: 0.894531\n",
      "Steps: 00860 Accuracy: 0.886719\n",
      "Steps: 00870 Accuracy: 0.875000\n",
      "Steps: 00880 Accuracy: 0.882812\n",
      "Steps: 00890 Accuracy: 0.875000\n",
      "Steps: 00900 Accuracy: 0.867188\n",
      "Steps: 00910 Accuracy: 0.855469\n",
      "Steps: 00920 Accuracy: 0.871094\n",
      "Steps: 00930 Accuracy: 0.816406\n",
      "\n",
      "Train Accuracy: 0.878856 Loss: 52425572.589117\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.867667 \n",
      "\n",
      "Epoch: 9\n",
      "Steps: 00940 Accuracy: 0.875000\n",
      "Steps: 00950 Accuracy: 0.898438\n",
      "Steps: 00960 Accuracy: 0.921875\n",
      "Steps: 00970 Accuracy: 0.894531\n",
      "Steps: 00980 Accuracy: 0.882812\n",
      "Steps: 00990 Accuracy: 0.898438\n",
      "Steps: 01000 Accuracy: 0.902344\n",
      "Steps: 01010 Accuracy: 0.890625\n",
      "Steps: 01020 Accuracy: 0.871094\n",
      "Steps: 01030 Accuracy: 0.875000\n",
      "Steps: 01040 Accuracy: 0.910156\n",
      "Steps: 01050 Accuracy: 0.871094\n",
      "\n",
      "Train Accuracy: 0.883813 Loss: 50328336.296719\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.862845 \n",
      "\n",
      "Epoch: 10\n",
      "Steps: 01060 Accuracy: 0.898438\n",
      "Steps: 01070 Accuracy: 0.859375\n",
      "Steps: 01080 Accuracy: 0.855469\n",
      "Steps: 01090 Accuracy: 0.933594\n",
      "Steps: 01100 Accuracy: 0.878906\n",
      "Steps: 01110 Accuracy: 0.894531\n",
      "Steps: 01120 Accuracy: 0.890625\n",
      "Steps: 01130 Accuracy: 0.917969\n",
      "Steps: 01140 Accuracy: 0.910156\n",
      "Steps: 01150 Accuracy: 0.902344\n",
      "Steps: 01160 Accuracy: 0.882812\n",
      "Steps: 01170 Accuracy: 0.894410\n",
      "\n",
      "Train Accuracy: 0.886727 Loss: 48481289.988157\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.864988 \n",
      "\n",
      "Epoch: 11\n",
      "Steps: 01180 Accuracy: 0.886719\n",
      "Steps: 01190 Accuracy: 0.878906\n",
      "Steps: 01200 Accuracy: 0.914062\n",
      "Steps: 01210 Accuracy: 0.910156\n",
      "Steps: 01220 Accuracy: 0.914062\n",
      "Steps: 01230 Accuracy: 0.882812\n",
      "Steps: 01240 Accuracy: 0.910156\n",
      "Steps: 01250 Accuracy: 0.871094\n",
      "Steps: 01260 Accuracy: 0.894531\n",
      "Steps: 01270 Accuracy: 0.875000\n",
      "Steps: 01280 Accuracy: 0.925781\n",
      "\n",
      "Train Accuracy: 0.891784 Loss: 46506786.879890\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.869810 \n",
      "\n",
      "Epoch: 12\n",
      "Steps: 01290 Accuracy: 0.890625\n",
      "Steps: 01300 Accuracy: 0.882812\n",
      "Steps: 01310 Accuracy: 0.906250\n",
      "Steps: 01320 Accuracy: 0.914062\n",
      "Steps: 01330 Accuracy: 0.847656\n",
      "Steps: 01340 Accuracy: 0.886719\n",
      "Steps: 01350 Accuracy: 0.902344\n",
      "Steps: 01360 Accuracy: 0.906250\n",
      "Steps: 01370 Accuracy: 0.894531\n",
      "Steps: 01380 Accuracy: 0.894531\n",
      "Steps: 01390 Accuracy: 0.910156\n",
      "Steps: 01400 Accuracy: 0.898438\n",
      "\n",
      "Train Accuracy: 0.895301 Loss: 45153609.309772\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.866327 \n",
      "\n",
      "Epoch: 13\n",
      "Steps: 01410 Accuracy: 0.871094\n",
      "Steps: 01420 Accuracy: 0.910156\n",
      "Steps: 01430 Accuracy: 0.878906\n",
      "Steps: 01440 Accuracy: 0.875000\n",
      "Steps: 01450 Accuracy: 0.886719\n",
      "Steps: 01460 Accuracy: 0.914062\n",
      "Steps: 01470 Accuracy: 0.910156\n",
      "Steps: 01480 Accuracy: 0.886719\n",
      "Steps: 01490 Accuracy: 0.898438\n",
      "Steps: 01500 Accuracy: 0.867188\n",
      "Steps: 01510 Accuracy: 0.894531\n",
      "Steps: 01520 Accuracy: 0.890625\n",
      "\n",
      "Train Accuracy: 0.897377 Loss: 43829824.198000\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.871685 \n",
      "\n",
      "Epoch: 14\n",
      "Steps: 01530 Accuracy: 0.914062\n",
      "Steps: 01540 Accuracy: 0.929688\n",
      "Steps: 01550 Accuracy: 0.917969\n",
      "Steps: 01560 Accuracy: 0.929688\n",
      "Steps: 01570 Accuracy: 0.910156\n",
      "Steps: 01580 Accuracy: 0.929688\n",
      "Steps: 01590 Accuracy: 0.890625\n",
      "Steps: 01600 Accuracy: 0.917969\n",
      "Steps: 01610 Accuracy: 0.890625\n",
      "Steps: 01620 Accuracy: 0.898438\n",
      "Steps: 01630 Accuracy: 0.867188\n",
      "\n",
      "Train Accuracy: 0.900660 Loss: 42688217.158158\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.877310 \n",
      "\n",
      "Epoch: 15\n",
      "Steps: 01640 Accuracy: 0.894531\n",
      "Steps: 01650 Accuracy: 0.894531\n",
      "Steps: 01660 Accuracy: 0.910156\n",
      "Steps: 01670 Accuracy: 0.917969\n",
      "Steps: 01680 Accuracy: 0.910156\n",
      "Steps: 01690 Accuracy: 0.886719\n",
      "Steps: 01700 Accuracy: 0.890625\n",
      "Steps: 01710 Accuracy: 0.933594\n",
      "Steps: 01720 Accuracy: 0.898438\n",
      "Steps: 01730 Accuracy: 0.906250\n",
      "Steps: 01740 Accuracy: 0.875000\n",
      "Steps: 01750 Accuracy: 0.890625\n",
      "\n",
      "Train Accuracy: 0.903574 Loss: 41344715.879921\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.870881 \n",
      "\n",
      "Epoch: 16\n",
      "Steps: 01760 Accuracy: 0.898438\n",
      "Steps: 01770 Accuracy: 0.898438\n",
      "Steps: 01780 Accuracy: 0.917969\n",
      "Steps: 01790 Accuracy: 0.906250\n",
      "Steps: 01800 Accuracy: 0.882812\n",
      "Steps: 01810 Accuracy: 0.925781\n",
      "Steps: 01820 Accuracy: 0.898438\n",
      "Steps: 01830 Accuracy: 0.941406\n",
      "Steps: 01840 Accuracy: 0.894531\n",
      "Steps: 01850 Accuracy: 0.914062\n",
      "Steps: 01860 Accuracy: 0.914062\n",
      "Steps: 01870 Accuracy: 0.894531\n",
      "\n",
      "Train Accuracy: 0.906253 Loss: 40310528.950843\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.869810 \n",
      "\n",
      "Epoch: 17\n",
      "Steps: 01880 Accuracy: 0.937500\n",
      "Steps: 01890 Accuracy: 0.921875\n",
      "Steps: 01900 Accuracy: 0.890625\n",
      "Steps: 01910 Accuracy: 0.914062\n",
      "Steps: 01920 Accuracy: 0.898438\n",
      "Steps: 01930 Accuracy: 0.906250\n",
      "Steps: 01940 Accuracy: 0.929688\n",
      "Steps: 01950 Accuracy: 0.878906\n",
      "Steps: 01960 Accuracy: 0.933594\n",
      "Steps: 01970 Accuracy: 0.925781\n",
      "Steps: 01980 Accuracy: 0.863281\n",
      "\n",
      "Train Accuracy: 0.907258 Loss: 39535349.190559\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.871685 \n",
      "\n",
      "Epoch: 18\n",
      "Steps: 01990 Accuracy: 0.875000\n",
      "Steps: 02000 Accuracy: 0.898438\n",
      "Steps: 02010 Accuracy: 0.937500\n",
      "Steps: 02020 Accuracy: 0.960938\n",
      "Steps: 02030 Accuracy: 0.941406\n",
      "Steps: 02040 Accuracy: 0.933594\n",
      "Steps: 02050 Accuracy: 0.945312\n",
      "Steps: 02060 Accuracy: 0.914062\n",
      "Steps: 02070 Accuracy: 0.898438\n",
      "Steps: 02080 Accuracy: 0.910156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 02090 Accuracy: 0.894531\n",
      "Steps: 02100 Accuracy: 0.941406\n",
      "\n",
      "Train Accuracy: 0.910842 Loss: 38201629.974572\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.874096 \n",
      "\n",
      "Epoch: 19\n",
      "Steps: 02110 Accuracy: 0.898438\n",
      "Steps: 02120 Accuracy: 0.886719\n",
      "Steps: 02130 Accuracy: 0.921875\n",
      "Steps: 02140 Accuracy: 0.910156\n",
      "Steps: 02150 Accuracy: 0.894531\n",
      "Steps: 02160 Accuracy: 0.929688\n",
      "Steps: 02170 Accuracy: 0.894531\n",
      "Steps: 02180 Accuracy: 0.910156\n",
      "Steps: 02190 Accuracy: 0.910156\n",
      "Steps: 02200 Accuracy: 0.910156\n",
      "Steps: 02210 Accuracy: 0.921875\n",
      "Steps: 02220 Accuracy: 0.945312\n",
      "\n",
      "Train Accuracy: 0.915732 Loss: 37110712.263007\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.879721 \n",
      "\n",
      "Epoch: 20\n",
      "Steps: 02230 Accuracy: 0.921875\n",
      "Steps: 02240 Accuracy: 0.902344\n",
      "Steps: 02250 Accuracy: 0.906250\n",
      "Steps: 02260 Accuracy: 0.941406\n",
      "Steps: 02270 Accuracy: 0.921875\n",
      "Steps: 02280 Accuracy: 0.917969\n",
      "Steps: 02290 Accuracy: 0.898438\n",
      "Steps: 02300 Accuracy: 0.894531\n",
      "Steps: 02310 Accuracy: 0.906250\n",
      "Steps: 02320 Accuracy: 0.929688\n",
      "Steps: 02330 Accuracy: 0.941406\n",
      "Steps: 02340 Accuracy: 0.881988\n",
      "\n",
      "Train Accuracy: 0.915330 Loss: 36568053.147005\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.878918 \n",
      "\n",
      "Epoch: 21\n",
      "Steps: 02350 Accuracy: 0.886719\n",
      "Steps: 02360 Accuracy: 0.894531\n",
      "Steps: 02370 Accuracy: 0.925781\n",
      "Steps: 02380 Accuracy: 0.914062\n",
      "Steps: 02390 Accuracy: 0.914062\n",
      "Steps: 02400 Accuracy: 0.929688\n",
      "Steps: 02410 Accuracy: 0.871094\n",
      "Steps: 02420 Accuracy: 0.902344\n",
      "Steps: 02430 Accuracy: 0.917969\n",
      "Steps: 02440 Accuracy: 0.917969\n",
      "Steps: 02450 Accuracy: 0.937500\n",
      "\n",
      "Train Accuracy: 0.915832 Loss: 35594087.782220\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.873828 \n",
      "\n",
      "Epoch: 22\n",
      "Steps: 02460 Accuracy: 0.914062\n",
      "Steps: 02470 Accuracy: 0.921875\n",
      "Steps: 02480 Accuracy: 0.917969\n",
      "Steps: 02490 Accuracy: 0.929688\n",
      "Steps: 02500 Accuracy: 0.941406\n",
      "Steps: 02510 Accuracy: 0.898438\n",
      "Steps: 02520 Accuracy: 0.949219\n",
      "Steps: 02530 Accuracy: 0.921875\n",
      "Steps: 02540 Accuracy: 0.914062\n",
      "Steps: 02550 Accuracy: 0.871094\n",
      "Steps: 02560 Accuracy: 0.886719\n",
      "Steps: 02570 Accuracy: 0.886719\n",
      "\n",
      "Train Accuracy: 0.918713 Loss: 34542525.263706\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.877310 \n",
      "\n",
      "Epoch: 23\n",
      "Steps: 02580 Accuracy: 0.921875\n",
      "Steps: 02590 Accuracy: 0.925781\n",
      "Steps: 02600 Accuracy: 0.917969\n",
      "Steps: 02610 Accuracy: 0.914062\n",
      "Steps: 02620 Accuracy: 0.925781\n",
      "Steps: 02630 Accuracy: 0.929688\n",
      "Steps: 02640 Accuracy: 0.890625\n",
      "Steps: 02650 Accuracy: 0.933594\n",
      "Steps: 02660 Accuracy: 0.906250\n",
      "Steps: 02670 Accuracy: 0.933594\n",
      "Steps: 02680 Accuracy: 0.929688\n",
      "Steps: 02690 Accuracy: 0.917969\n",
      "\n",
      "Train Accuracy: 0.920454 Loss: 34117228.881177\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.878918 \n",
      "\n",
      "Epoch: 24\n",
      "Steps: 02700 Accuracy: 0.941406\n",
      "Steps: 02710 Accuracy: 0.917969\n",
      "Steps: 02720 Accuracy: 0.941406\n",
      "Steps: 02730 Accuracy: 0.917969\n",
      "Steps: 02740 Accuracy: 0.910156\n",
      "Steps: 02750 Accuracy: 0.925781\n",
      "Steps: 02760 Accuracy: 0.863281\n",
      "Steps: 02770 Accuracy: 0.933594\n",
      "Steps: 02780 Accuracy: 0.914062\n",
      "Steps: 02790 Accuracy: 0.925781\n",
      "Steps: 02800 Accuracy: 0.910156\n",
      "\n",
      "Train Accuracy: 0.922296 Loss: 33250271.073678\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.882132 \n",
      "\n",
      "Epoch: 25\n",
      "Steps: 02810 Accuracy: 0.933594\n",
      "Steps: 02820 Accuracy: 0.933594\n",
      "Steps: 02830 Accuracy: 0.949219\n",
      "Steps: 02840 Accuracy: 0.941406\n",
      "Steps: 02850 Accuracy: 0.949219\n",
      "Steps: 02860 Accuracy: 0.925781\n",
      "Steps: 02870 Accuracy: 0.941406\n",
      "Steps: 02880 Accuracy: 0.937500\n",
      "Steps: 02890 Accuracy: 0.968750\n",
      "Steps: 02900 Accuracy: 0.949219\n",
      "Steps: 02910 Accuracy: 0.914062\n",
      "Steps: 02920 Accuracy: 0.933594\n",
      "\n",
      "Train Accuracy: 0.924708 Loss: 32578464.161373\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.878918 \n",
      "\n",
      "Epoch: 26\n",
      "Steps: 02930 Accuracy: 0.925781\n",
      "Steps: 02940 Accuracy: 0.921875\n",
      "Steps: 02950 Accuracy: 0.929688\n",
      "Steps: 02960 Accuracy: 0.953125\n",
      "Steps: 02970 Accuracy: 0.929688\n",
      "Steps: 02980 Accuracy: 0.902344\n",
      "Steps: 02990 Accuracy: 0.929688\n",
      "Steps: 03000 Accuracy: 0.917969\n",
      "Steps: 03010 Accuracy: 0.941406\n",
      "Steps: 03020 Accuracy: 0.898438\n",
      "Steps: 03030 Accuracy: 0.949219\n",
      "Steps: 03040 Accuracy: 0.925781\n",
      "\n",
      "Train Accuracy: 0.924205 Loss: 31932982.953525\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.880793 \n",
      "\n",
      "Epoch: 27\n",
      "Steps: 03050 Accuracy: 0.921875\n",
      "Steps: 03060 Accuracy: 0.906250\n",
      "Steps: 03070 Accuracy: 0.949219\n",
      "Steps: 03080 Accuracy: 0.960938\n",
      "Steps: 03090 Accuracy: 0.929688\n",
      "Steps: 03100 Accuracy: 0.925781\n",
      "Steps: 03110 Accuracy: 0.921875\n",
      "Steps: 03120 Accuracy: 0.921875\n",
      "Steps: 03130 Accuracy: 0.906250\n",
      "Steps: 03140 Accuracy: 0.941406\n",
      "Steps: 03150 Accuracy: 0.949219\n",
      "\n",
      "Train Accuracy: 0.926416 Loss: 31470209.740821\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.883204 \n",
      "\n",
      "Epoch: 28\n",
      "Steps: 03160 Accuracy: 0.917969\n",
      "Steps: 03170 Accuracy: 0.957031\n",
      "Steps: 03180 Accuracy: 0.875000\n",
      "Steps: 03190 Accuracy: 0.933594\n",
      "Steps: 03200 Accuracy: 0.937500\n",
      "Steps: 03210 Accuracy: 0.910156\n",
      "Steps: 03220 Accuracy: 0.917969\n",
      "Steps: 03230 Accuracy: 0.949219\n",
      "Steps: 03240 Accuracy: 0.910156\n",
      "Steps: 03250 Accuracy: 0.949219\n",
      "Steps: 03260 Accuracy: 0.945312\n",
      "Steps: 03270 Accuracy: 0.921875\n",
      "\n",
      "Train Accuracy: 0.927320 Loss: 30984923.791622\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.881329 \n",
      "\n",
      "Epoch: 29\n",
      "Steps: 03280 Accuracy: 0.914062\n",
      "Steps: 03290 Accuracy: 0.929688\n",
      "Steps: 03300 Accuracy: 0.894531\n",
      "Steps: 03310 Accuracy: 0.921875\n",
      "Steps: 03320 Accuracy: 0.921875\n",
      "Steps: 03330 Accuracy: 0.902344\n",
      "Steps: 03340 Accuracy: 0.937500\n",
      "Steps: 03350 Accuracy: 0.937500\n",
      "Steps: 03360 Accuracy: 0.933594\n",
      "Steps: 03370 Accuracy: 0.925781\n",
      "Steps: 03380 Accuracy: 0.925781\n",
      "Steps: 03390 Accuracy: 0.910156\n",
      "\n",
      "Train Accuracy: 0.928425 Loss: 30532497.387374\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.880257 \n",
      "\n",
      "Epoch: 30\n",
      "Steps: 03400 Accuracy: 0.933594\n",
      "Steps: 03410 Accuracy: 0.914062\n",
      "Steps: 03420 Accuracy: 0.921875\n",
      "Steps: 03430 Accuracy: 0.941406\n",
      "Steps: 03440 Accuracy: 0.933594\n",
      "Steps: 03450 Accuracy: 0.917969\n",
      "Steps: 03460 Accuracy: 0.925781\n",
      "Steps: 03470 Accuracy: 0.937500\n",
      "Steps: 03480 Accuracy: 0.925781\n",
      "Steps: 03490 Accuracy: 0.937500\n",
      "Steps: 03500 Accuracy: 0.917969\n",
      "Steps: 03510 Accuracy: 0.962733\n",
      "\n",
      "Train Accuracy: 0.930703 Loss: 30149581.044026\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.884275 \n",
      "\n",
      "Epoch: 31\n",
      "Steps: 03520 Accuracy: 0.921875\n",
      "Steps: 03530 Accuracy: 0.937500\n",
      "Steps: 03540 Accuracy: 0.937500\n",
      "Steps: 03550 Accuracy: 0.949219\n",
      "Steps: 03560 Accuracy: 0.921875\n",
      "Steps: 03570 Accuracy: 0.960938\n",
      "Steps: 03580 Accuracy: 0.902344\n",
      "Steps: 03590 Accuracy: 0.925781\n",
      "Steps: 03600 Accuracy: 0.914062\n",
      "Steps: 03610 Accuracy: 0.941406\n",
      "Steps: 03620 Accuracy: 0.933594\n",
      "\n",
      "Train Accuracy: 0.933081 Loss: 29388378.883421\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.882400 \n",
      "\n",
      "Epoch: 32\n",
      "Steps: 03630 Accuracy: 0.933594\n",
      "Steps: 03640 Accuracy: 0.933594\n",
      "Steps: 03650 Accuracy: 0.929688\n",
      "Steps: 03660 Accuracy: 0.917969\n",
      "Steps: 03670 Accuracy: 0.925781\n",
      "Steps: 03680 Accuracy: 0.917969\n",
      "Steps: 03690 Accuracy: 0.925781\n",
      "Steps: 03700 Accuracy: 0.953125\n",
      "Steps: 03710 Accuracy: 0.964844\n",
      "Steps: 03720 Accuracy: 0.925781\n",
      "Steps: 03730 Accuracy: 0.921875\n",
      "Steps: 03740 Accuracy: 0.941406\n",
      "\n",
      "Train Accuracy: 0.934052 Loss: 28718300.291980\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.882936 \n",
      "\n",
      "Epoch: 33\n",
      "Steps: 03750 Accuracy: 0.945312\n",
      "Steps: 03760 Accuracy: 0.937500\n",
      "Steps: 03770 Accuracy: 0.906250\n",
      "Steps: 03780 Accuracy: 0.937500\n",
      "Steps: 03790 Accuracy: 0.910156\n",
      "Steps: 03800 Accuracy: 0.957031\n",
      "Steps: 03810 Accuracy: 0.929688\n",
      "Steps: 03820 Accuracy: 0.925781\n",
      "Steps: 03830 Accuracy: 0.949219\n",
      "Steps: 03840 Accuracy: 0.937500\n",
      "Steps: 03850 Accuracy: 0.941406\n",
      "Steps: 03860 Accuracy: 0.914062\n",
      "\n",
      "Train Accuracy: 0.935693 Loss: 28058010.782051\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.886418 \n",
      "\n",
      "Epoch: 34\n",
      "Steps: 03870 Accuracy: 0.933594\n",
      "Steps: 03880 Accuracy: 0.957031\n",
      "Steps: 03890 Accuracy: 0.945312\n",
      "Steps: 03900 Accuracy: 0.953125\n",
      "Steps: 03910 Accuracy: 0.957031\n",
      "Steps: 03920 Accuracy: 0.968750\n",
      "Steps: 03930 Accuracy: 0.949219\n",
      "Steps: 03940 Accuracy: 0.937500\n",
      "Steps: 03950 Accuracy: 0.925781\n",
      "Steps: 03960 Accuracy: 0.921875\n",
      "Steps: 03970 Accuracy: 0.921875\n",
      "\n",
      "Train Accuracy: 0.937268 Loss: 27473874.669009\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.883204 \n",
      "\n",
      "Epoch: 35\n",
      "Steps: 03980 Accuracy: 0.933594\n",
      "Steps: 03990 Accuracy: 0.937500\n",
      "Steps: 04000 Accuracy: 0.949219\n",
      "Steps: 04010 Accuracy: 0.929688\n",
      "Steps: 04020 Accuracy: 0.929688\n",
      "Steps: 04030 Accuracy: 0.925781\n",
      "Steps: 04040 Accuracy: 0.953125\n",
      "Steps: 04050 Accuracy: 0.929688\n",
      "Steps: 04060 Accuracy: 0.890625\n",
      "Steps: 04070 Accuracy: 0.910156\n",
      "Steps: 04080 Accuracy: 0.917969\n",
      "Steps: 04090 Accuracy: 0.953125\n",
      "\n",
      "Train Accuracy: 0.937100 Loss: 27279281.215278\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.888294 \n",
      "\n",
      "Epoch: 36\n",
      "Steps: 04100 Accuracy: 0.945312\n",
      "Steps: 04110 Accuracy: 0.910156\n",
      "Steps: 04120 Accuracy: 0.945312\n",
      "Steps: 04130 Accuracy: 0.960938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 04140 Accuracy: 0.925781\n",
      "Steps: 04150 Accuracy: 0.937500\n",
      "Steps: 04160 Accuracy: 0.937500\n",
      "Steps: 04170 Accuracy: 0.960938\n",
      "Steps: 04180 Accuracy: 0.957031\n",
      "Steps: 04190 Accuracy: 0.929688\n",
      "Steps: 04200 Accuracy: 0.937500\n",
      "Steps: 04210 Accuracy: 0.917969\n",
      "\n",
      "Train Accuracy: 0.937335 Loss: 26780453.796290\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.884275 \n",
      "\n",
      "Epoch: 37\n",
      "Steps: 04220 Accuracy: 0.953125\n",
      "Steps: 04230 Accuracy: 0.929688\n",
      "Steps: 04240 Accuracy: 0.953125\n",
      "Steps: 04250 Accuracy: 0.937500\n",
      "Steps: 04260 Accuracy: 0.941406\n",
      "Steps: 04270 Accuracy: 0.933594\n",
      "Steps: 04280 Accuracy: 0.949219\n",
      "Steps: 04290 Accuracy: 0.953125\n",
      "Steps: 04300 Accuracy: 0.902344\n",
      "Steps: 04310 Accuracy: 0.898438\n",
      "Steps: 04320 Accuracy: 0.941406\n",
      "\n",
      "Train Accuracy: 0.938909 Loss: 26352083.406085\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.888294 \n",
      "\n",
      "Epoch: 38\n",
      "Steps: 04330 Accuracy: 0.941406\n",
      "Steps: 04340 Accuracy: 0.945312\n",
      "Steps: 04350 Accuracy: 0.957031\n",
      "Steps: 04360 Accuracy: 0.910156\n",
      "Steps: 04370 Accuracy: 0.941406\n",
      "Steps: 04380 Accuracy: 0.917969\n",
      "Steps: 04390 Accuracy: 0.945312\n",
      "Steps: 04400 Accuracy: 0.921875\n",
      "Steps: 04410 Accuracy: 0.941406\n",
      "Steps: 04420 Accuracy: 0.945312\n",
      "Steps: 04430 Accuracy: 0.937500\n",
      "Steps: 04440 Accuracy: 0.945312\n",
      "\n",
      "Train Accuracy: 0.941019 Loss: 26230550.067811\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.886151 \n",
      "\n",
      "Epoch: 39\n",
      "Steps: 04450 Accuracy: 0.945312\n",
      "Steps: 04460 Accuracy: 0.960938\n",
      "Steps: 04470 Accuracy: 0.921875\n",
      "Steps: 04480 Accuracy: 0.941406\n",
      "Steps: 04490 Accuracy: 0.945312\n",
      "Steps: 04500 Accuracy: 0.937500\n",
      "Steps: 04510 Accuracy: 0.941406\n",
      "Steps: 04520 Accuracy: 0.933594\n",
      "Steps: 04530 Accuracy: 0.953125\n",
      "Steps: 04540 Accuracy: 0.953125\n",
      "Steps: 04550 Accuracy: 0.933594\n",
      "Steps: 04560 Accuracy: 0.945312\n",
      "\n",
      "Train Accuracy: 0.942894 Loss: 25648172.557022\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.889097 \n",
      "\n",
      "Epoch: 40\n",
      "Steps: 04570 Accuracy: 0.945312\n",
      "Steps: 04580 Accuracy: 0.941406\n",
      "Steps: 04590 Accuracy: 0.937500\n",
      "Steps: 04600 Accuracy: 0.960938\n",
      "Steps: 04610 Accuracy: 0.949219\n",
      "Steps: 04620 Accuracy: 0.968750\n",
      "Steps: 04630 Accuracy: 0.906250\n",
      "Steps: 04640 Accuracy: 0.945312\n",
      "Steps: 04650 Accuracy: 0.910156\n",
      "Steps: 04660 Accuracy: 0.933594\n",
      "Steps: 04670 Accuracy: 0.953125\n",
      "Steps: 04680 Accuracy: 0.937888\n",
      "\n",
      "Train Accuracy: 0.943062 Loss: 25248970.812788\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.890437 \n",
      "\n",
      "Epoch: 41\n",
      "Steps: 04690 Accuracy: 0.945312\n",
      "Steps: 04700 Accuracy: 0.953125\n",
      "Steps: 04710 Accuracy: 0.953125\n",
      "Steps: 04720 Accuracy: 0.949219\n",
      "Steps: 04730 Accuracy: 0.941406\n",
      "Steps: 04740 Accuracy: 0.929688\n",
      "Steps: 04750 Accuracy: 0.949219\n",
      "Steps: 04760 Accuracy: 0.960938\n",
      "Steps: 04770 Accuracy: 0.929688\n",
      "Steps: 04780 Accuracy: 0.949219\n",
      "Steps: 04790 Accuracy: 0.933594\n",
      "\n",
      "Train Accuracy: 0.943665 Loss: 24719205.385764\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.888026 \n",
      "\n",
      "Epoch: 42\n",
      "Steps: 04800 Accuracy: 0.945312\n",
      "Steps: 04810 Accuracy: 0.976562\n",
      "Steps: 04820 Accuracy: 0.957031\n",
      "Steps: 04830 Accuracy: 0.949219\n",
      "Steps: 04840 Accuracy: 0.929688\n",
      "Steps: 04850 Accuracy: 0.960938\n",
      "Steps: 04860 Accuracy: 0.937500\n",
      "Steps: 04870 Accuracy: 0.957031\n",
      "Steps: 04880 Accuracy: 0.957031\n",
      "Steps: 04890 Accuracy: 0.941406\n",
      "Steps: 04900 Accuracy: 0.949219\n",
      "Steps: 04910 Accuracy: 0.949219\n",
      "\n",
      "Train Accuracy: 0.944871 Loss: 24447390.983517\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.886686 \n",
      "\n",
      "Epoch: 43\n",
      "Steps: 04920 Accuracy: 0.960938\n",
      "Steps: 04930 Accuracy: 0.949219\n",
      "Steps: 04940 Accuracy: 0.976562\n",
      "Steps: 04950 Accuracy: 0.957031\n",
      "Steps: 04960 Accuracy: 0.949219\n",
      "Steps: 04970 Accuracy: 0.945312\n",
      "Steps: 04980 Accuracy: 0.960938\n",
      "Steps: 04990 Accuracy: 0.917969\n",
      "Steps: 05000 Accuracy: 0.957031\n",
      "Steps: 05010 Accuracy: 0.933594\n",
      "Steps: 05020 Accuracy: 0.945312\n",
      "Steps: 05030 Accuracy: 0.941406\n",
      "\n",
      "Train Accuracy: 0.945574 Loss: 23874084.443433\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.886954 \n",
      "\n",
      "Epoch: 44\n",
      "Steps: 05040 Accuracy: 0.949219\n",
      "Steps: 05050 Accuracy: 0.953125\n",
      "Steps: 05060 Accuracy: 0.937500\n",
      "Steps: 05070 Accuracy: 0.933594\n",
      "Steps: 05080 Accuracy: 0.953125\n",
      "Steps: 05090 Accuracy: 0.949219\n",
      "Steps: 05100 Accuracy: 0.960938\n",
      "Steps: 05110 Accuracy: 0.937500\n",
      "Steps: 05120 Accuracy: 0.925781\n",
      "Steps: 05130 Accuracy: 0.949219\n",
      "Steps: 05140 Accuracy: 0.949219\n",
      "\n",
      "Train Accuracy: 0.947650 Loss: 23518047.398860\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.887758 \n",
      "\n",
      "Epoch: 45\n",
      "Steps: 05150 Accuracy: 0.976562\n",
      "Steps: 05160 Accuracy: 0.921875\n",
      "Steps: 05170 Accuracy: 0.957031\n",
      "Steps: 05180 Accuracy: 0.937500\n",
      "Steps: 05190 Accuracy: 0.937500\n",
      "Steps: 05200 Accuracy: 0.929688\n",
      "Steps: 05210 Accuracy: 0.960938\n",
      "Steps: 05220 Accuracy: 0.941406\n",
      "Steps: 05230 Accuracy: 0.957031\n",
      "Steps: 05240 Accuracy: 0.968750\n",
      "Steps: 05250 Accuracy: 0.921875\n",
      "Steps: 05260 Accuracy: 0.933594\n",
      "\n",
      "Train Accuracy: 0.947784 Loss: 23315546.191947\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.890972 \n",
      "\n",
      "Epoch: 46\n",
      "Steps: 05270 Accuracy: 0.941406\n",
      "Steps: 05280 Accuracy: 0.945312\n",
      "Steps: 05290 Accuracy: 0.933594\n",
      "Steps: 05300 Accuracy: 0.941406\n",
      "Steps: 05310 Accuracy: 0.964844\n",
      "Steps: 05320 Accuracy: 0.968750\n",
      "Steps: 05330 Accuracy: 0.937500\n",
      "Steps: 05340 Accuracy: 0.941406\n",
      "Steps: 05350 Accuracy: 0.960938\n",
      "Steps: 05360 Accuracy: 0.960938\n",
      "Steps: 05370 Accuracy: 0.949219\n",
      "Steps: 05380 Accuracy: 0.937500\n",
      "\n",
      "Train Accuracy: 0.948588 Loss: 23074620.452012\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.889901 \n",
      "\n",
      "Epoch: 47\n",
      "Steps: 05390 Accuracy: 0.957031\n",
      "Steps: 05400 Accuracy: 0.957031\n",
      "Steps: 05410 Accuracy: 0.964844\n",
      "Steps: 05420 Accuracy: 0.925781\n",
      "Steps: 05430 Accuracy: 0.980469\n",
      "Steps: 05440 Accuracy: 0.945312\n",
      "Steps: 05450 Accuracy: 0.945312\n",
      "Steps: 05460 Accuracy: 0.925781\n",
      "Steps: 05470 Accuracy: 0.937500\n",
      "Steps: 05480 Accuracy: 0.937500\n",
      "Steps: 05490 Accuracy: 0.957031\n",
      "\n",
      "Train Accuracy: 0.948689 Loss: 22680511.267234\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.888829 \n",
      "\n",
      "Epoch: 48\n",
      "Steps: 05500 Accuracy: 0.929688\n",
      "Steps: 05510 Accuracy: 0.960938\n",
      "Steps: 05520 Accuracy: 0.933594\n",
      "Steps: 05530 Accuracy: 0.953125\n",
      "Steps: 05540 Accuracy: 0.925781\n",
      "Steps: 05550 Accuracy: 0.949219\n",
      "Steps: 05560 Accuracy: 0.929688\n",
      "Steps: 05570 Accuracy: 0.968750\n",
      "Steps: 05580 Accuracy: 0.945312\n",
      "Steps: 05590 Accuracy: 0.957031\n",
      "Steps: 05600 Accuracy: 0.933594\n",
      "Steps: 05610 Accuracy: 0.949219\n",
      "\n",
      "Train Accuracy: 0.949627 Loss: 22398807.938540\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.890169 \n",
      "\n",
      "Epoch: 49\n",
      "Steps: 05620 Accuracy: 0.949219\n",
      "Steps: 05630 Accuracy: 0.945312\n",
      "Steps: 05640 Accuracy: 0.964844\n",
      "Steps: 05650 Accuracy: 0.937500\n",
      "Steps: 05660 Accuracy: 0.964844\n",
      "Steps: 05670 Accuracy: 0.960938\n",
      "Steps: 05680 Accuracy: 0.953125\n",
      "Steps: 05690 Accuracy: 0.957031\n",
      "Steps: 05700 Accuracy: 0.964844\n",
      "Steps: 05710 Accuracy: 0.953125\n",
      "Steps: 05720 Accuracy: 0.945312\n",
      "Steps: 05730 Accuracy: 0.941406\n",
      "\n",
      "Train Accuracy: 0.951636 Loss: 22147873.819226\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.892580 \n",
      "\n",
      "Epoch: 50\n",
      "Steps: 05740 Accuracy: 0.925781\n",
      "Steps: 05750 Accuracy: 0.937500\n",
      "Steps: 05760 Accuracy: 0.953125\n",
      "Steps: 05770 Accuracy: 0.945312\n",
      "Steps: 05780 Accuracy: 0.921875\n",
      "Steps: 05790 Accuracy: 0.957031\n",
      "Steps: 05800 Accuracy: 0.949219\n",
      "Steps: 05810 Accuracy: 0.957031\n",
      "Steps: 05820 Accuracy: 0.945312\n",
      "Steps: 05830 Accuracy: 0.933594\n",
      "Steps: 05840 Accuracy: 0.925781\n",
      "Steps: 05850 Accuracy: 0.944099\n",
      "\n",
      "Train Accuracy: 0.952808 Loss: 21852106.006930\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.888829 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model end evaluate on our validation set\n",
    "ic_loss_list = []\n",
    "ic_train_acc_list = []\n",
    "ic_val_acc_list = []\n",
    "\n",
    "ic_steps = 0\n",
    "for epoch in range(1, options['ic_epochs'] + 1):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    \n",
    "    # variables to keep track of our average loss and accuracy\n",
    "    ic_loss_avg = 0\n",
    "    train_acc_avg = 0\n",
    "\n",
    "    # run batched training\n",
    "    for batch_idxs in get_batch_idxs(len(X_train), options['batch_size']):\n",
    "        \n",
    "        _, accur, curr_cls_loss = sess.run(\n",
    "            [cls_train_op, cls_acc, cls_loss], feed_dict= {\n",
    "                im: X_train[batch_idxs], \n",
    "                y: y_train[batch_idxs]\n",
    "            })\n",
    "        \n",
    "        ic_steps += 1\n",
    "        \n",
    "        # update average loss and accuracy\n",
    "        ic_loss_avg += curr_cls_loss * len(batch_idxs) / float(len(X_train))\n",
    "        train_acc_avg += accur * len(batch_idxs) / float(len(X_train))\n",
    "\n",
    "        if ic_steps % 10 == 0:\n",
    "            print(\"Steps: %05d Accuracy: %f\" % (\n",
    "                ic_steps, accur))\n",
    "\n",
    "    print()\n",
    "    print(\"Train Accuracy: %f Loss: %f\\n\" % (\n",
    "            train_acc_avg, \n",
    "            ic_loss_avg\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ic_loss_list.append(ic_loss_avg)\n",
    "    ic_train_acc_list.append(train_acc_avg)\n",
    "    \n",
    "    # variables to keep track of our average val loss and accuracy\n",
    "    val_acc_avg = 0\n",
    "    \n",
    "    # get validation accuracy in batches\n",
    "    for batch_idxs in get_batch_idxs(len(X_val), options['batch_size']):\n",
    "        [curr_val_accur] = sess.run(\n",
    "            [cls_acc], feed_dict={ \n",
    "                im: X_val[batch_idxs], \n",
    "                y: y_val[batch_idxs]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        val_acc_avg += curr_val_accur * len(batch_idxs) / float(len(X_val))\n",
    "\n",
    "    print(\"\\nValidation Accuracy: %f \\n\" % (val_acc_avg))\n",
    "    \n",
    "    ic_val_acc_list.append(val_acc_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchial results:\tPrecision: 0.88\tRecall: 0.93\n"
     ]
    }
   ],
   "source": [
    "#Calculate hierarchical recall and precision\n",
    "\n",
    "index2name = {v:k for k,v in name2index.items()}\n",
    "\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "idxs_order = []\n",
    "\n",
    "val_errors = []\n",
    "for batch_idxs in get_batch_idxs(len(X_val), options['batch_size']):\n",
    "    [val_pred, curr_val_errors] = sess.run(\n",
    "        [flat_hit_pred, cls_all_errors], feed_dict={ \n",
    "            im: X_val[batch_idxs], \n",
    "            y: y_val[batch_idxs]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ground_truth.extend(y_val[batch_idxs])\n",
    "    predicted.extend(val_pred)\n",
    "\n",
    "    val_errors.extend(curr_val_errors)\n",
    "\n",
    "y_val_hier = [hypernyms_per_class[int(l)] for l in ground_truth]\n",
    "\n",
    "prec = []\n",
    "recall = []\n",
    "for idx in range(len(X_val)):\n",
    "    pred_hier = val_errors[idx] <= min(val_errors[idx][:options['num_base_classes']])\n",
    "    curr_precision = sum(y_val_hier[idx] * pred_hier) / sum(pred_hier)\n",
    "    curr_recall = sum(y_val_hier[idx] * pred_hier) / sum(y_val_hier[idx])\n",
    "\n",
    "    prec.append(curr_precision)\n",
    "    recall.append(curr_recall)\n",
    "\n",
    "print(\"Hierarchial results:\\tPrecision: %.2f\\tRecall: %.2f\" % (np.mean(prec),np.mean(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat hit accuracy:\t@ 1: 0.8888\t@ 3: 0.9657\t@ 5: 0.9778\t@ 10: 0.9896\n"
     ]
    }
   ],
   "source": [
    "# calculate flat hit accuracy\n",
    "flat_hit_at_1 = 0\n",
    "flat_hit_at_3 = 0\n",
    "flat_hit_at_5 = 0\n",
    "flat_hit_at_10 = 0\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    try:\n",
    "        found_idx = list(predicted[i]).index(ground_truth[i])\n",
    "    except:\n",
    "        found_idx = 9999999\n",
    "\n",
    "    if found_idx < 1:\n",
    "        flat_hit_at_1 += 1.0 / len(X_val)\n",
    "    if found_idx < 3:\n",
    "        flat_hit_at_3 += 1.0 / len(X_val)\n",
    "    if found_idx < 5:\n",
    "        flat_hit_at_5 += 1.0 / len(X_val)\n",
    "    if found_idx < 10:\n",
    "        flat_hit_at_10 += 1.0 / len(X_val)\n",
    "\n",
    "\n",
    "print(\"Flat hit accuracy:\\t@ 1: %.4f\\t@ 3: %.4f\\t@ 5: %.4f\\t@ 10: %.4f\" % (\n",
    "    flat_hit_at_1,\n",
    "    flat_hit_at_3,\n",
    "    flat_hit_at_5,\n",
    "    flat_hit_at_10\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
